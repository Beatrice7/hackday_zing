<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
<body>
  <div id="navbar"></div>
  <div class="center-content page-container">

    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <div style="position: relative" class="margin">
      <!--
      <video src="bbt.mp4" id="inputVideo" autoplay muted loop playsinline></video>
      <canvas id="overlay" />
      -->
      <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
      <canvas id="overlay" />
    </div>

    <div class="row side-by-side">

      <!-- face_detector_selection_control -->
      <div id="face_detector_selection_control" class="row input-field" style="margin-right: 20px;">
        <select id="selectFaceDetector">
          <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
          <option value="tiny_face_detector">Tiny Face Detector</option>
          <option value="mtcnn">MTCNN</option>
        </select>
        <label>Select Face Detector</label>
      </div>
      <!-- face_detector_selection_control -->

      <!-- check boxes -->
      <div class="row" style="width: 220px;">
        <input type="checkbox" id="withFaceLandmarksCheckbox" onchange="onChangeWithFaceLandmarks(event)" />
        <label for="withFaceLandmarksCheckbox">Detect Face Landmarks</label>
        <input type="checkbox" id="hideBoundingBoxesCheckbox" onchange="onChangeHideBoundingBoxes(event)" />
        <label for="hideBoundingBoxesCheckbox">Hide Bounding Boxes</label>
      </div>
      <!-- check boxes -->

      <!-- fps_meter -->
      <div id="fps_meter" class="row side-by-side">
        <div>
          <label for="time">Time:</label>
          <input disabled value="-" id="time" type="text" class="bold">
          <label for="fps">Estimated Fps:</label>
          <input disabled value="-" id="fps" type="text" class="bold">
        </div>
      </div>
      <!-- fps_meter -->

    </div>

    <!-- ssd_mobilenetv1_controls -->
    <span id="ssd_mobilenetv1_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minConfidence">Min Confidence:</label>
          <input disabled value="0.5" id="minConfidence" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinConfidence()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinConfidence()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- ssd_mobilenetv1_controls -->

    <!-- tiny_face_detector_controls -->
    <span id="tiny_face_detector_controls">
      <div class="row side-by-side">
        <div class="row input-field" style="margin-right: 20px;">
          <select id="inputSize">
            <option value="" disabled selected>Input Size:</option>
            <option value="160">160 x 160</option>
            <option value="224">224 x 224</option>
            <option value="320">320 x 320</option>
            <option value="416">416 x 416</option>
            <option value="512">512 x 512</option>
            <option value="608">608 x 608</option>
          </select>
          <label>Input Size</label>
        </div>
        <div class="row">
          <label for="scoreThreshold">Score Threshold:</label>
          <input disabled value="0.5" id="scoreThreshold" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseScoreThreshold()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseScoreThreshold()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- tiny_face_detector_controls -->

    <!-- mtcnn_controls -->
    <span id="mtcnn_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minFaceSize">Minimum Face Size:</label>
          <input disabled value="20" id="minFaceSize" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinFaceSize()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinFaceSize()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- mtcnn_controls -->

  </body>

  <script>
    let forwardTimes = []
    let withFaceLandmarks = false
    let withBoxes = true

    function onChangeWithFaceLandmarks(e) {
      withFaceLandmarks = $(e.target).prop('checked')
    }

    function onChangeHideBoundingBoxes(e) {
      withBoxes = !$(e.target).prop('checked')
    }

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
    }

    async function onPlay(videoEl) {
      if(!videoEl.currentTime || videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay(videoEl))


      const options = getFaceDetectorOptions()

      const ts = Date.now()

      const drawBoxes = withBoxes
      const drawLandmarks = withFaceLandmarks

      /*
      let task = faceapi.detectAllFaces(videoEl, options)
      task = withFaceLandmarks ? task.withFaceLandmarks() : task
      const results = await task

      updateTimeStats(Date.now() - ts)

      const canvas = $('#overlay').get(0)
      const dims = faceapi.matchDimensions(canvas, videoEl, true)

      const resizedResults = faceapi.resizeResults(results, dims)
      if (drawBoxes) {
        faceapi.draw.drawDetections(canvas, resizedResults)
      }
      if (drawLandmarks) {
        faceapi.draw.drawFaceLandmarks(canvas, resizedResults)
      }

      setTimeout(() => onPlay(videoEl))
      */

      // var fullFaceDescription = null

      // const labels = ['sheldon', 'raj', 'leonard', 'howard']
      const labels = ['raj']
      const labeledFaceDescriptors = await Promise.all(
        labels.map(async label => {
          // fetch image data from urls and convert blob to HTMLImage element
          const imgUrl = `${label}/${label}1.png`
          const img = await faceapi.fetchImage(imgUrl)
          
          const options = getFaceDetectorOptions()

          // detect the face with the highest score in the image and compute it's landmarks and face descriptor
          const fullFaceDescription = await faceapi
  .detectAllFaces(img, options)
  .withFaceLandmarks()
  .withFaceDescriptors()
          // const fullFaceDescription = await faceapi.detectAllFaces(img, options).withFaceLandmarks().withFaceDescriptors()
          //const fullFaceDescription = await faceapi.detectSingleFace(img, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptor()
          
          // if (!fullFaceDescription) {
          //   throw new Error(`no faces detected for ${label}`)
          // }
          
          const faceDescriptors = [fullFaceDescription[0].descriptor]
          return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
        })
      )
      
     /* workable2
      const imgUrl = `raj/raj1.png`
          const img = await faceapi.fetchImage(imgUrl)
          const options3 = getFaceDetectorOptions()

          // detect the face with the highest score in the image and compute it's landmarks and face descriptor
          // const fullFaceDescription = await faceapi.detectSingleFace(img, options).withFaceLandmarks().withFaceDescriptor()
          const results = await faceapi
  .detectAllFaces(img, options3)
  .withFaceLandmarks()
  .withFaceDescriptors()
*/
      /*
      const mtcnnForwardParams = {
        // limiting the search space to larger faces for webcam detection
        minFaceSize: 200
      }
      const options2 = new faceapi.MtcnnOptions(mtcnnForwardParams)
      const input = document.getElementById('inputVideo')
      const fullFaceDescriptions = await faceapi.detectAllFaces(input, options2).withFaceLandmarks().withFaceDescriptors()
      */

      const maxDescriptorDistance = 0.6
const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)

const results = labeledFaceDescriptors.map(fd => faceMatcher.findBestMatch(fd.descriptors))
      setTimeout(() => onPlay(videoEl))

      results.forEach((bestMatch, i) => {
  const box = labeledFaceDescriptors[i].detection.box
  const text = bestMatch.toString()
  const drawBox = new faceapi.draw.DrawBox(box, { label: text })
  drawBox.draw(canvas)
})
    }

    /*
    async function run() {
      // load face detection and face landmark models
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceLandmarkModel('/')
      changeInputSize(416)

      // start processing frames
      onPlay($('#inputVideo').get(0))
    } */

    async function run() {
      /*
      // load face detection model
      await changeFaceDetector(TINY_FACE_DETECTOR)
      changeInputSize(128)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
      */

      // load face detection and face landmark models
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceLandmarkModel('/')
      // await faceapi.nets.faceLandmark68Net.loadFromUri('/models')
      // await faceapi.nets.ssdMobilenetv1.loadFromUri('/')
      
      await faceapi.loadFaceRecognitionModel('/')
      await faceapi.loadTinyFaceDetectorModel('/')

      await faceapi.loadMtcnnModel('/')
      await faceapi.loadSsdMobilenetv1Model('/')

      changeInputSize(416)

      // start processing frames
      //onPlay($('#inputVideo').get(0))
      
      // try to access users webcam and stream the images
      // to the video element
      const videoEl = document.getElementById('inputVideo')
      navigator.getUserMedia(
        { video: {} },
        stream => videoEl.srcObject = stream,
        err => console.error(err)
      )
    }

    function updateResults() {}

    $(document).ready(function() {
      renderNavBar('#navbar', 'video_face_tracking')
      initFaceDetectionControls()
      run()
    })
    
  </script>
</body>
</html>